{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbfc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, stanza, pathlib\n",
    "from tqdm import tqdm\n",
    "from stanza.utils.conll import CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c627ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path('C:/Users/Vignir/PycharmProjects/SUDcom/dataset')  \n",
    "FILES = [\n",
    "    BASE_DIR / 'A2.csv',\n",
    "    BASE_DIR / 'B2.csv',\n",
    "    BASE_DIR / 'C2.csv',\n",
    "    BASE_DIR / 'cefr_leveled_texts.csv',    \n",
    "]\n",
    "LANG  = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea416fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for f in FILES:\n",
    "    if os.path.exists(f):\n",
    "        dfs.append(pd.read_csv(f, encoding=\"utf-8\"))\n",
    "if not dfs:\n",
    "    raise FileNotFoundError(\"None of the CSVs were found. Check FILES paths.\")\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "if \"text\" not in data.columns:\n",
    "    raise ValueError(\"CSV must contain a 'text' column.\")\n",
    "data = data.dropna(subset=[\"text\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc9e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stanza.download(LANG, processors=\"tokenize,mwt,pos,lemma,depparse\", verbose=False)\n",
    "except Exception:\n",
    "    pass\n",
    "nlp = stanza.Pipeline(lang=LANG, processors=\"tokenize,pos,lemma,depparse\", use_gpu=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93cc306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [00:50<01:42,  1.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, txt \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[1;32m----> 5\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     lab \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m][i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, sent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc\u001b[38;5;241m.\u001b[39msentences, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stanza\\pipeline\\core.py:480\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc, processors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stanza\\pipeline\\core.py:431\u001b[0m, in \u001b[0;36mPipeline.process\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mget(processor_name):\n\u001b[0;32m    430\u001b[0m         process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mbulk_process \u001b[38;5;28;01mif\u001b[39;00m bulk \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mprocess\n\u001b[1;32m--> 431\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stanza\\pipeline\\mwt_processor.py:40\u001b[0m, in \u001b[0;36mMWTProcessor.process\u001b[1;34m(self, document)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     39\u001b[0m     preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch\u001b[38;5;241m.\u001b[39mto_loader()):\n\u001b[0;32m     41\u001b[0m         preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mpredict(b, never_decode_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, vocab\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble_dict\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stanza\\models\\mwt\\data.py:135\u001b[0m, in \u001b[0;36mDataLoader.__collate_fn\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    132\u001b[0m lens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m src]\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# convert to tensors\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPAD_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meq(src, constant\u001b[38;5;241m.\u001b[39mPAD_ID)\n\u001b[0;32m    137\u001b[0m tgt_in \u001b[38;5;241m=\u001b[39m pad_sequence(tgt_in, \u001b[38;5;28;01mTrue\u001b[39;00m, constant\u001b[38;5;241m.\u001b[39mPAD_ID)\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\utils\\rnn.py:474\u001b[0m, in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value, padding_side)\u001b[0m\n\u001b[0;32m    470\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    479\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%env OMP_NUM_THREADS=4\n",
    "rows = []\n",
    "data = data.head(200)\n",
    "for i, txt in tqdm(enumerate(data[\"text\"].astype(str), start=1), total=len(data)):\n",
    "    doc = nlp(txt)\n",
    "    lab = data[\"label\"][i-1] if \"label\" in data.columns else None\n",
    "    for j, sent in enumerate(doc.sentences, start=1):\n",
    "        for w in sent.words:\n",
    "            rows.append({\n",
    "                \"doc_id\": i,\n",
    "                \"sent_id\": j,\n",
    "                \"token_id\": w.id,\n",
    "                \"form\": w.text,\n",
    "                \"lemma\": w.lemma,\n",
    "                \"upos\": w.upos,\n",
    "                \"xpos\": w.xpos or \"_\",\n",
    "                \"head\": w.head,\n",
    "                \"deprel\": w.deprel,\n",
    "                **({\"label\": lab} if lab is not None else {})\n",
    "            })\n",
    "\n",
    "tagged = pd.DataFrame(rows)\n",
    "display(tagged.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f52af1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conll \u001b[38;5;241m=\u001b[39m \u001b[43mCoNLL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtagged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stanza\\utils\\conll.py:89\u001b[0m, in \u001b[0;36mCoNLL.convert_dict\u001b[1;34m(doc_dict)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_dict\u001b[39m(doc_dict):\n\u001b[0;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Convert the dictionary format input data to the CoNLL-U format output data.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    This is the reverse function of `convert_conll`, but does not include sentence level annotations or comments.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    Output: CoNLL-U format data as a list of list of list for each token in each sentence in the data.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:c}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(doc)\n\u001b[0;32m     91\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stanza\\models\\common\\doc.py:80\u001b[0m, in \u001b[0;36mDocument.__init__\u001b[1;34m(self, sentences, text, comments, empty_sentences)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mempty_sentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coref \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Vignir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stanza\\models\\common\\doc.py:182\u001b[0m, in \u001b[0;36mDocument._process_sentences\u001b[1;34m(self, sentences, comments, empty_sentences)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m empty_sentences \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     empty_sentences \u001b[38;5;241m=\u001b[39m repeat([])\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent_idx, (tokens, empty_words) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mempty_sentences\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m         sentence \u001b[38;5;241m=\u001b[39m Sentence(tokens, doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, empty_words\u001b[38;5;241m=\u001b[39mempty_words)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "conll = CoNLL.convert_dict(tagged.to_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

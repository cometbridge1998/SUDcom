{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbfc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, stanza, pathlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c627ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path('C:/Users/Vignir/PycharmProjects/SUDcom/dataset')  \n",
    "FILES = [\n",
    "    BASE_DIR / 'A1.csv',\n",
    "    BASE_DIR / 'B2.csv',\n",
    "    BASE_DIR / 'C2.csv',\n",
    "    BASE_DIR / 'cefr_leveled_texts.csv',    \n",
    "]\n",
    "LANG  = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea416fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for f in FILES:\n",
    "    if os.path.exists(f):\n",
    "        dfs.append(pd.read_csv(f, encoding=\"utf-8\"))\n",
    "if not dfs:\n",
    "    raise FileNotFoundError(\"None of the CSVs were found. Check FILES paths.\")\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "if \"text\" not in data.columns:\n",
    "    raise ValueError(\"CSV must contain a 'text' column.\")\n",
    "data = data.dropna(subset=[\"text\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc9e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stanza.download(LANG, processors=\"tokenize,pos,lemma,depparse\", verbose=False)\n",
    "except Exception:\n",
    "    pass\n",
    "nlp = stanza.Pipeline(lang=LANG, processors=\"tokenize,pos,lemma,depparse\", use_gpu=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93cc306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:00<00:14,  1.31it/s]"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "data = data.head(200)\n",
    "for i, txt in tqdm(enumerate(data[\"text\"].astype(str), start=1), total=len(data)):\n",
    "    doc = nlp(txt)\n",
    "    lab = data[\"label\"][i-1] if \"label\" in data.columns else None\n",
    "    for j, sent in enumerate(doc.sentences, start=1):\n",
    "        for w in sent.words:\n",
    "            rows.append({\n",
    "                \"doc_id\": i,\n",
    "                \"sent_id\": j,\n",
    "                \"token_id\": w.id,\n",
    "                \"form\": w.text,\n",
    "                \"lemma\": w.lemma,\n",
    "                \"upos\": w.upos,\n",
    "                \"xpos\": w.xpos or \"_\",\n",
    "                \"head\": w.head,\n",
    "                \"deprel\": w.deprel,\n",
    "                **({\"label\": lab} if lab is not None else {})\n",
    "            })\n",
    "\n",
    "tagged = pd.DataFrame(rows)\n",
    "display(tagged.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
